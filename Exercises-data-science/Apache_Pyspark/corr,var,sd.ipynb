{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd=sc.parallelize([103]+[1,100,200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.rdd.RDD"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rdd) #case sensitive\n",
    "#lambda function programming\n",
    "#lambda argument_list: expression \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[103, 1]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(2)#must specify argument so shows limitied only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[103, 1, 100, 200]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.collect() #shows entire data with exact structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "101.0"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average\n",
    "mean=rdd.sum()/float(rdd.count()) #float otherwise round off type problem -precison due to implict conversion cast to int\n",
    "print(mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 100, 103, 200]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#median same as mean but extreme values less effect on it due to sorting\n",
    "rdd.sortBy(lambda x:x).collect()    #sort the list and middle value if two numbers average it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 0), (100, 1), (103, 2), (200, 3)]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.sortBy(lambda x:x).zipWithIndex().collect() #adding index to each entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 1), (1, 100), (2, 103), (3, 200)]\n",
      "<class 'pyspark.rdd.PipelinedRDD'>\n"
     ]
    }
   ],
   "source": [
    "sortedindex=rdd.sortBy(lambda x:x).zipWithIndex().map(lambda (value,key) : (key,value)) # value key only working in python 2.0\n",
    "# if .collect() used at end it will display but type of object changing to list and count not working\n",
    "print(sortedindex.take(10))\n",
    "print(type(sortedindex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(rdd.sortBy(lambda x:x).zipWithIndex().map(lambda (value,key) : (key,value)).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "103\n",
      "101\n"
     ]
    }
   ],
   "source": [
    "cn=sortedindex.count()\n",
    "if (cn%2 ==1):\n",
    "    index=(cn-1)/2 #\n",
    "    print sortedindex.lookup(index) #checks whats at that index from above\n",
    "else:\n",
    "    index1=(cn/2)-1\n",
    "    index2=cn/2\n",
    "    v1=sortedindex.lookup(index1)[0]\n",
    "    v2=sortedindex.lookup(index2)[0] #lookup returns list to get rid of it\n",
    "    print v1\n",
    "    print v2\n",
    "    print(((v1+v2)/2))\n",
    "    #median far more resistant to outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "#covariance by variance of different varaibles gives correlation\n",
    "rddx=sc.parallelize([1,2,3,4,5,6,7,8,9,10])\n",
    "rddy=sc.parallelize([7,6,5,4,5,6,7,8,9,10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "mx=rddx.sum()/float(rddx.count())\n",
    "my=rddy.sum()/float(rddy.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 7), (2, 6)]"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rddxy=rddx.zip(rddy) #for both accessing at a same time\n",
    "rddxy.take(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.65"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "covxy=rddxy.map(lambda (x,y):(x-mx)*(y-my)).sum()/float(rddx.count())\n",
    "covxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.8722813232690143"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "n=rddxy.count()\n",
    "sdx=sqrt(rddx.map(lambda x:pow(x-mx,2)).sum()/float(rddx.count()))\n",
    "sdy=sqrt(rddy.map(lambda y:pow(y-my,2)).sum()/float(rddy.count()))\n",
    "sdx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.709272912083725"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrxy=covxy/float(sdx*sdy)\n",
    "corrxy\n",
    "#correlation tells which colunks intersting are correlated to each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from pyspark.mllib.stat import Statistics\n",
    "c1=sc.parallelize(range(100))\n",
    "c2=sc.parallelize(range(100,200))\n",
    "c3=sc.parallelize(list(reversed(range(100)))) #list plz check\n",
    "c4=sc.parallelize(random.sample(range(100),100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0, 100, 99, 41],\n",
       " [1, 101, 98, 48],\n",
       " [2, 102, 97, 8],\n",
       " [3, 103, 96, 72],\n",
       " [4, 104, 95, 46],\n",
       " [5, 105, 94, 39],\n",
       " [6, 106, 93, 6],\n",
       " [7, 107, 92, 75],\n",
       " [8, 108, 91, 80],\n",
       " [9, 109, 90, 22]]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=c1.zip(c2).zip(c3).zip(c4).map(lambda (((a,b),c),d):(a,b,c,d)).map(lambda (a,b,c,d):[a,b,c,d]) #nested tuple input to normal tuple output and need list for rdd as output\n",
    "data.take(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.        , -1.        ,  0.04682868],\n",
       "       [ 1.        ,  1.        , -1.        ,  0.04682868],\n",
       "       [-1.        , -1.        ,  1.        , -0.04682868],\n",
       "       [ 0.04682868,  0.04682868, -0.04682868,  1.        ]])"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Statistics.corr(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
